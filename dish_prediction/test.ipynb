{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2c64244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded.\n",
      "\n",
      "Parsing utilities ready.\n",
      "\n",
      "Loaded rows: 21321\n",
      "Restaurant dummy columns added: ['rest_Aura Pizzas', 'rest_Dilli Burger Adda', 'rest_Masala Junction', 'rest_Swaad', 'rest_Tandoori Junction'] ...\n",
      "                                      Items in order  \\\n",
      "0  1 x Grilled Chicken Jamaican Tender, 1 x Grill...   \n",
      "1  1 x Peri Peri Fries, 1 x Fried Chicken Angara ...   \n",
      "2              1 x Bone in Peri Peri Grilled Chicken   \n",
      "3  1 x Fried Chicken Ghostbuster Tender, 1 x Anga...   \n",
      "4  1 x Peri Peri Krispers, 1 x Fried Chicken Anga...   \n",
      "\n",
      "                                      expanded_items  \n",
      "0  {'Grilled Chicken Jamaican Tender': 1, 'Grille...  \n",
      "1  {'Peri Peri Fries': 1, 'Fried Chicken Angara T...  \n",
      "2           {'Bone in Peri Peri Grilled Chicken': 1}  \n",
      "3  {'Fried Chicken Ghostbuster Tender': 1, 'Angar...  \n",
      "4  {'Peri Peri Krispers': 1, 'Fried Chicken Angar...  \n",
      "Top 50 dishes sample: ['Bageecha Pizza', 'Chilli Cheese Garlic Bread', 'Bone in Jamaican Grilled Chicken', 'All About Chicken Pizza', 'Makhani Paneer Pizza', 'Margherita Pizza', 'Cheesy Garlic Bread', 'Jamaican Chicken Melt', 'Herbed Potato', 'Tripple Cheese Pizza']\n",
      "Aggregated hours: 3673\n",
      "X shape: (3673, 9)\n",
      "Y shape: (3673, 50)\n",
      "Train hours: 2938 Test hours: 735\n",
      "Baseline RMSE: 0.5180696960354211\n",
      "Baseline R²: 0.055346252497040026\n",
      "Training RandomForest...\n",
      "RandomForest RMSE: 0.4918990626701158\n",
      "RandomForest R²: 0.0438561920350961\n",
      "Training XGBoost...\n",
      "XGBoost RMSE: 0.5177928263323136\n",
      "XGBoost R²: -0.08139116317033768\n",
      "Training CatBoost...\n",
      "CatBoost RMSE: 0.474922053104943\n",
      "CatBoost R²: 0.10096176118060997\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SIMPLIFIED DISHES-PER-HOUR PREDICTION NOTEBOOK (WITHOUT WEATHER AND POLLUTION)\n",
    "# Author: Your Name\n",
    "# Date: 2025-10-27\n",
    "# Goal: Predict hourly dish demand based on date and restaurant data only\n",
    "# =============================================================================\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1. IMPORTS & CONFIG\n",
    "# --------------------------------------------------------------\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import joblib\n",
    "import warnings\n",
    "from datetime import timedelta\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- CONFIG ---\n",
    "DATA_PATH = \"../data/data.csv\"\n",
    "TOP_K = 50\n",
    "RANDOM_STATE = 42\n",
    "MODEL_OUTPUT_DIR = \"models_no_weather\"\n",
    "os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Configuration loaded.\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2. UTILITY FUNCTIONS\n",
    "# --------------------------------------------------------------\n",
    "def parse_order_items(order_str: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"Parse '2 x Pizza, 1 x Coke' into [('Pizza', 2), ('Coke', 1)]. Returns empty list if parsing fails.\"\"\"\n",
    "    if pd.isna(order_str):\n",
    "        return []\n",
    "    parts = re.findall(r\"(\\d+)\\s*[xX]\\s*([^,]+)\", order_str)\n",
    "    out = []\n",
    "    for qty, name in parts:\n",
    "        item_name = name.strip()\n",
    "        try:\n",
    "            q = int(qty)\n",
    "        except ValueError:\n",
    "            q = 1\n",
    "        out.append((item_name, q))\n",
    "    return out\n",
    "\n",
    "assert parse_order_items('2 x Pizza, 1 x Coke') == [('Pizza', 2), ('Coke', 1)]\n",
    "print(\"Parsing utilities ready.\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4. LOAD & PREPROCESS DATA\n",
    "# --------------------------------------------------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "if 'Order Placed At' in df.columns:\n",
    "    df['order_datetime'] = pd.to_datetime(df['Order Placed At'], format=\"%I:%M %p, %B %d %Y\")\n",
    "df['order_hour'] = df['order_datetime'].dt.floor('h')\n",
    "print('Loaded rows:', len(df))\n",
    "\n",
    "restaurant_dummies = pd.get_dummies(df['Restaurant name'], prefix='rest')\n",
    "df = pd.concat([df, restaurant_dummies], axis=1)\n",
    "REST_NAMES = restaurant_dummies.columns.tolist()\n",
    "print(\"Restaurant dummy columns added:\", REST_NAMES[:5], \"...\")\n",
    "\n",
    "def expand_items_row(order_str: str) -> Dict[str, int]:\n",
    "    parsed = parse_order_items(order_str)\n",
    "    d = {}\n",
    "    for name, q in parsed:\n",
    "        d[name] = d.get(name, 0) + q\n",
    "    return d\n",
    "\n",
    "df['expanded_items'] = df['Items in order'].fillna('').apply(expand_items_row)\n",
    "print(df[['Items in order', 'expanded_items']].head())\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5. BUILD HOURLY AGGREGATION TABLE\n",
    "# --------------------------------------------------------------\n",
    "all_items = Counter()\n",
    "for d in df['expanded_items']:\n",
    "    all_items.update(d)\n",
    "TOP_K = min(TOP_K, len(all_items))\n",
    "TOP_DISHES = [name for name, _ in all_items.most_common(TOP_K)]\n",
    "print(f\"Top {TOP_K} dishes sample:\", TOP_DISHES[:10])\n",
    "\n",
    "hour_index = pd.date_range(start=df['order_hour'].min().floor('D'),\n",
    "                           end=df['order_hour'].max().ceil('D'), freq='h')\n",
    "agg = pd.DataFrame(index=hour_index)\n",
    "agg.index.name = 'order_hour'\n",
    "\n",
    "agg['hour_of_day'] = agg.index.hour\n",
    "agg['day_of_week'] = agg.index.dayofweek\n",
    "agg['is_weekend'] = agg['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "for dish in TOP_DISHES:\n",
    "    agg[f'dish__{dish}'] = 0\n",
    "agg['total_orders'] = 0\n",
    "for rest_col in REST_NAMES:\n",
    "    agg[rest_col] = 0\n",
    "\n",
    "for hour, group in df.groupby('order_hour'):\n",
    "    if hour in agg.index:\n",
    "        agg.loc[hour, 'total_orders'] = len(group)\n",
    "        for rest_col in REST_NAMES:\n",
    "            agg.loc[hour, rest_col] = group[rest_col].sum()\n",
    "        hour_counts = Counter()\n",
    "        for d in group['expanded_items']:\n",
    "            hour_counts.update(d)\n",
    "        for dish in TOP_DISHES:\n",
    "            agg.loc[hour, f'dish__{dish}'] = hour_counts.get(dish, 0)\n",
    "\n",
    "valid_hours = agg['total_orders'].rolling(window=24, min_periods=1).sum() >= 1\n",
    "agg = agg[valid_hours]\n",
    "print('Aggregated hours:', agg.shape[0])\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 7. PREPARE FEATURES AND TARGETS\n",
    "# --------------------------------------------------------------\n",
    "target_cols = [f'dish__{d}' for d in TOP_DISHES]\n",
    "feature_cols = ['hour_of_day', 'day_of_week', 'is_weekend']\n",
    "feature_cols += [c for c in agg.columns if c.startswith('rest_')]\n",
    "feature_cols = list(set(feature_cols))\n",
    "\n",
    "X = agg[feature_cols].copy()\n",
    "Y = agg[target_cols].copy()\n",
    "\n",
    "# Ensure all feature columns are numeric\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].astype('category').cat.codes\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce').fillna(0)\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('Y shape:', Y.shape)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 8. TRAIN/TEST SPLIT\n",
    "# --------------------------------------------------------------\n",
    "train_frac = 0.8\n",
    "train_size = int(len(X) * train_frac)\n",
    "\n",
    "X_train = X.iloc[:train_size].copy()\n",
    "X_test = X.iloc[train_size:].copy()\n",
    "Y_train = Y.iloc[:train_size]\n",
    "Y_test = Y.iloc[train_size:]\n",
    "\n",
    "print('Train hours:', X_train.shape[0], 'Test hours:', X_test.shape[0])\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 9. BASELINE MODEL\n",
    "# --------------------------------------------------------------\n",
    "baseline_preds = []\n",
    "for idx, row in X_test.iterrows():\n",
    "    hour = row['hour_of_day']\n",
    "    mask = X_train['hour_of_day'] == hour\n",
    "    if mask.sum() == 0:\n",
    "        baseline_preds.append(Y_train.mean().values)\n",
    "    else:\n",
    "        baseline_preds.append(Y_train[mask].mean().values)\n",
    "\n",
    "baseline_preds = np.vstack(baseline_preds)\n",
    "assert baseline_preds.shape == Y_test.shape\n",
    "\n",
    "baseline_rmse = np.sqrt(mean_squared_error(Y_test.values, baseline_preds))\n",
    "baseline_r2 = r2_score(Y_test.values, baseline_preds, multioutput='uniform_average')\n",
    "print('Baseline RMSE:', baseline_rmse)\n",
    "print('Baseline R²:', baseline_r2)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 10. MODELS\n",
    "# --------------------------------------------------------------\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "model = MultiOutputRegressor(rf)\n",
    "print('Training RandomForest...')\n",
    "model.fit(X_train, Y_train.values)\n",
    "preds = model.predict(X_test)\n",
    "rf_rmse = np.sqrt(mean_squared_error(Y_test.values, preds))\n",
    "rf_r2 = r2_score(Y_test.values, preds, multioutput='uniform_average')\n",
    "print('RandomForest RMSE:', rf_rmse)\n",
    "print('RandomForest R²:', rf_r2)\n",
    "joblib.dump({'model': model, 'top_dishes': TOP_DISHES, 'feature_cols': feature_cols},\n",
    "            os.path.join(MODEL_OUTPUT_DIR, 'rf_multioutput_v2.joblib'))\n",
    "\n",
    "xgb_model = MultiOutputRegressor(\n",
    "    xgb.XGBRegressor(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=RANDOM_STATE, n_jobs=-1, objective='reg:squarederror', enable_categorical=False)\n",
    ")\n",
    "print('Training XGBoost...')\n",
    "xgb_model.fit(X_train, Y_train.values)\n",
    "xgb_preds = xgb_model.predict(X_test)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(Y_test.values, xgb_preds))\n",
    "xgb_r2 = r2_score(Y_test.values, xgb_preds, multioutput='uniform_average')\n",
    "print('XGBoost RMSE:', xgb_rmse)\n",
    "print('XGBoost R²:', xgb_r2)\n",
    "\n",
    "catboost_model = MultiOutputRegressor(\n",
    "    CatBoostRegressor(iterations=200, depth=6, learning_rate=0.1, random_seed=RANDOM_STATE, verbose=0, thread_count=-1)\n",
    ")\n",
    "print('Training CatBoost...')\n",
    "catboost_model.fit(X_train, Y_train.values)\n",
    "catboost_preds = catboost_model.predict(X_test)\n",
    "catboost_rmse = np.sqrt(mean_squared_error(Y_test.values, catboost_preds))\n",
    "catboost_r2 = r2_score(Y_test.values, catboost_preds, multioutput='uniform_average')\n",
    "print('CatBoost RMSE:', catboost_rmse)\n",
    "print('CatBoost R²:', catboost_r2)\n",
    "\n",
    "# Store scaling parameters\n",
    "X_train_means = X_train.mean()\n",
    "X_train_stds = X_train.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4533721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction for 2025-10-28 12:00 (CatBoost):\n",
      "                                      dish  predicted_qty\n",
      "0                     dish__Bageecha Pizza              1\n",
      "5                   dish__Margherita Pizza              1\n",
      "38                dish__Spinach Sumac Pide              0\n",
      "28   dish__Peri Peri Grilled Chicken Pizza              0\n",
      "29      dish__Fried Chicken Classic Tender              0\n",
      "30  dish__Grilled Chicken Smoky BBQ Tender              0\n",
      "31       dish__Fried Chicken Angara Tender              0\n",
      "32  dish__Grilled Chicken Peri Peri Tender              0\n",
      "33            dish__Peri Peri Chicken Melt              0\n",
      "34            dish__Pepperoni Garlic Bread              0\n",
      "35                      dish__Garlic Aioli              0\n",
      "36                   dish__Peri Peri Fries              0\n",
      "37            dish__Bellpepper Onion Pizza              0\n",
      "39                 dish__Mutton Seekh Pide              0\n",
      "26    dish__Bone in Angara Grilled Chicken              0\n",
      "40       dish__Tipsy Tiger Fresh Lime Soda              0\n",
      "41              dish__Fried Chicken Strips              0\n",
      "42                       dish__Onion Rings              0\n",
      "43           dish__Chicken Pepperoni Pizza              0\n",
      "44                    dish__OG Cheese Pide              0\n",
      "\n",
      "Prediction for 2025-10-28 12:00 (XGBoost):\n",
      "                                      dish  predicted_qty\n",
      "0                     dish__Bageecha Pizza              2\n",
      "5                   dish__Margherita Pizza              1\n",
      "7              dish__Jamaican Chicken Melt              1\n",
      "38                dish__Spinach Sumac Pide              0\n",
      "28   dish__Peri Peri Grilled Chicken Pizza              0\n",
      "29      dish__Fried Chicken Classic Tender              0\n",
      "30  dish__Grilled Chicken Smoky BBQ Tender              0\n",
      "31       dish__Fried Chicken Angara Tender              0\n",
      "32  dish__Grilled Chicken Peri Peri Tender              0\n",
      "33            dish__Peri Peri Chicken Melt              0\n",
      "34            dish__Pepperoni Garlic Bread              0\n",
      "35                      dish__Garlic Aioli              0\n",
      "36                   dish__Peri Peri Fries              0\n",
      "37            dish__Bellpepper Onion Pizza              0\n",
      "39                 dish__Mutton Seekh Pide              0\n",
      "26    dish__Bone in Angara Grilled Chicken              0\n",
      "40       dish__Tipsy Tiger Fresh Lime Soda              0\n",
      "41              dish__Fried Chicken Strips              0\n",
      "42                       dish__Onion Rings              0\n",
      "43           dish__Chicken Pepperoni Pizza              0\n",
      "\n",
      "Prediction for 2025-10-28 12:00 (RandomForest):\n",
      "                                      dish  predicted_qty\n",
      "0                     dish__Bageecha Pizza              1\n",
      "2   dish__Bone in Jamaican Grilled Chicken              1\n",
      "5                   dish__Margherita Pizza              1\n",
      "6                dish__Cheesy Garlic Bread              1\n",
      "7              dish__Jamaican Chicken Melt              1\n",
      "18   dish__Grilled Chicken Jamaican Tender              1\n",
      "38                dish__Spinach Sumac Pide              0\n",
      "30  dish__Grilled Chicken Smoky BBQ Tender              0\n",
      "31       dish__Fried Chicken Angara Tender              0\n",
      "32  dish__Grilled Chicken Peri Peri Tender              0\n",
      "33            dish__Peri Peri Chicken Melt              0\n",
      "34            dish__Pepperoni Garlic Bread              0\n",
      "35                      dish__Garlic Aioli              0\n",
      "36                   dish__Peri Peri Fries              0\n",
      "37            dish__Bellpepper Onion Pizza              0\n",
      "41              dish__Fried Chicken Strips              0\n",
      "39                 dish__Mutton Seekh Pide              0\n",
      "40       dish__Tipsy Tiger Fresh Lime Soda              0\n",
      "28   dish__Peri Peri Grilled Chicken Pizza              0\n",
      "42                       dish__Onion Rings              0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------------------------------------------\n",
    "# 13. INFERENCE\n",
    "# --------------------------------------------------------------\n",
    "def build_inference_row(dt_hour, context_row=None):\n",
    "    dt_hour = pd.to_datetime(dt_hour).floor('h')\n",
    "    base = pd.Series(X_train_means, index=feature_cols, dtype=float)\n",
    "    \n",
    "    base['hour_of_day'] = dt_hour.hour\n",
    "    base['day_of_week'] = dt_hour.dayofweek\n",
    "    base['is_weekend'] = int(dt_hour.dayofweek in [5, 6])\n",
    "    \n",
    "    # Scale continuous features\n",
    "    continuous_cols = ['hour_of_day', 'day_of_week']\n",
    "    for col in continuous_cols:\n",
    "        if col in base.index and X_train_stds[col] != 0:\n",
    "            base[col] = (base[col] - X_train_means[col]) / X_train_stds[col]\n",
    "    \n",
    "    # Apply context if provided\n",
    "    if context_row:\n",
    "        for k, v in context_row.items():\n",
    "            if k in base.index:\n",
    "                base[k] = v\n",
    "    \n",
    "    return pd.DataFrame([base]).reindex(columns=feature_cols)\n",
    "\n",
    "def predict_for_hour(dt_hour, context_row=None, top_n=20, round_to_int=True, use_model='CatBoost'):\n",
    "    x_row = build_inference_row(dt_hour, context_row)\n",
    "    \n",
    "    # Ensure x_row is numeric\n",
    "    for col in x_row.columns:\n",
    "        x_row[col] = pd.to_numeric(x_row[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    # Select model\n",
    "    if use_model == 'CatBoost':\n",
    "        selected_model = catboost_model\n",
    "    elif use_model == 'XGBoost':\n",
    "        selected_model = xgb_model\n",
    "    elif use_model == 'RandomForest':\n",
    "        selected_model = model\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {use_model}\")\n",
    "    \n",
    "    pred = selected_model.predict(x_row).reshape(-1)\n",
    "    if round_to_int:\n",
    "        pred = np.round(pred).astype(int)\n",
    "    return pd.DataFrame({'dish': Y_train.columns, 'predicted_qty': pred}) \\\n",
    "        .sort_values('predicted_qty', ascending=False).head(top_n)\n",
    "\n",
    "# Example prediction\n",
    "example_date = \"2025-10-28 12:00\"\n",
    "print(f\"\\nPrediction for {example_date} (CatBoost):\")\n",
    "print(predict_for_hour(example_date, use_model='CatBoost'))\n",
    "print(f\"\\nPrediction for {example_date} (XGBoost):\")\n",
    "print(predict_for_hour(example_date, use_model='XGBoost'))\n",
    "print(f\"\\nPrediction for {example_date} (RandomForest):\")\n",
    "print(predict_for_hour(example_date, use_model='RandomForest'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3029694a",
   "metadata": {},
   "source": [
    "### Comparative Analysis of Prediction Models: With and Without Weather and Pollution Data\n",
    "\n",
    "#### What We Are Predicting\n",
    "Both models predict the hourly demand for the top 50 most frequently ordered dishes (e.g., \"Bageecha Pizza\", \"Chilli Cheese Garlic Bread\", \"Margherita Pizza\") across 3,673 aggregated hours, derived from 21,321 order records. The goal is to forecast the number of orders for each dish, with the \"with weather and pollution\" model incorporating environmental factors (weather conditions and AQI), while the \"without\" model relies solely on temporal and restaurant-specific data. These predictions support restaurant inventory and staffing decisions, with the key difference being the inclusion of environmental influences in the former.\n",
    "\n",
    "#### Results Comparison\n",
    "The performance metrics for the test set (735 hours) from both models are as follows:\n",
    "\n",
    "- **Baseline Model** (Both):\n",
    "  - RMSE: 0.5181\n",
    "  - R²: 0.0553\n",
    "  - The baseline, which predicts demand using the average for each hour of the day from the training data (2,938 hours), is identical across both models. This consistency reflects its reliance on temporal data alone, unaffected by the addition of weather and pollution features.\n",
    "\n",
    "- **RandomForest**:\n",
    "  - With Weather and Pollution:\n",
    "    - RMSE: 0.4853\n",
    "    - R²: 0.0373\n",
    "  - Without Weather and Pollution:\n",
    "    - RMSE: 0.4919\n",
    "    - R²: 0.0439\n",
    "  - RandomForest performs slightly better in RMSE (0.4853 vs. 0.4919) with weather and pollution, but its R² is lower (0.0373 vs. 0.0439), suggesting that environmental features may introduce noise or overfitting, reducing explanatory power.\n",
    "\n",
    "- **XGBoost**:\n",
    "  - With Weather and Pollution:\n",
    "    - RMSE: 0.5200\n",
    "    - R²: -0.1203\n",
    "  - Without Weather and Pollution:\n",
    "    - RMSE: 0.5178\n",
    "    - R²: -0.0814\n",
    "  - XGBoost performs worse than the baseline in both cases, with a negative R² indicating poor fit. Removing weather and pollution improves R² (-0.0814 vs. -0.1203) and slightly reduces RMSE (0.5178 vs. 0.5200), suggesting environmental data may confuse the model or require better tuning.\n",
    "\n",
    "- **CatBoost**:\n",
    "  - With Weather and Pollution:\n",
    "    - RMSE: 0.4817\n",
    "    - R²: 0.0610\n",
    "  - Without Weather and Pollution:\n",
    "    - RMSE: 0.4749\n",
    "    - R²: 0.1010\n",
    "  - CatBoost shows the best performance overall. Without weather and pollution, it achieves a lower RMSE (0.4749 vs. 0.4817) and a significantly higher R² (0.1010 vs. 0.0610), indicating that removing environmental features improves its accuracy and explanatory power.\n",
    "\n",
    "#### Features Used\n",
    "- **With Weather and Pollution**:\n",
    "  - **Temporal Features**: `hour_of_day`, `day_of_week`, `is_weekend`, `is_weekend_or_holiday`.\n",
    "  - **Weather Features**: `temperature`, `humidity`, `precipitation`, `wind_speed`, `weather_condition` (one-hot encoded).\n",
    "  - **Pollution Feature**: `aqi`.\n",
    "  - **Restaurant Features**: Dummy variables (e.g., `rest_Aura Pizzas`).\n",
    "  - X shape: (3673, 15), reflecting the additional environmental features.\n",
    "- **Without Weather and Pollution**:\n",
    "  - **Temporal Features**: `hour_of_day`, `day_of_week`, `is_weekend`.\n",
    "  - **Restaurant Features**: Dummy variables (e.g., `rest_Aura Pizzas`).\n",
    "  - X shape: (3673, 9), with fewer features due to the exclusion of weather and pollution.\n",
    "\n",
    "The \"with\" model includes 6 additional environmental features, which expand the feature space but may introduce complexity or noise if not strongly correlated with demand.\n",
    "\n",
    "#### Where the Data Came From\n",
    "- **Order Data**: Both models use `data.csv` with 21,321 rows, parsed from the \"Items in order\" column to extract dish quantities, likely from a restaurant management system.\n",
    "- **Weather Data** (With Model Only): Sourced via the `meteostat` library, fetched based on predefined coordinates for restaurants and subzones (e.g., Aura Pizzas at [28.55, 77.25]).\n",
    "- **Pollution Data** (With Model Only): Obtained from `pollution.csv`, merged by hourly timestamps to provide AQI values.\n",
    "- The \"without\" model relies solely on the order data, eliminating the need for external weather and pollution sources.\n",
    "\n",
    "#### Significance of the Results\n",
    "- **Predictive Insight**:\n",
    "  - The \"with\" model’s inclusion of weather and pollution slightly worsens CatBoost’s R² (0.0610 vs. 0.1010) and increases RMSE (0.4817 vs. 0.4749), suggesting that these features may not be strongly predictive or may introduce noise in this dataset. The baseline R² (0.0553) being close to both models’ R² values indicates that temporal patterns dominate demand.\n",
    "  - The \"without\" model’s higher R² (0.1010 for CatBoost) suggests that simplifying the feature set improves the model’s ability to generalize, possibly because weather and AQI data lack a clear correlation with demand in this context.\n",
    "\n",
    "- **Model Performance**:\n",
    "  - CatBoost consistently outperforms RandomForest and XGBoost in both setups, with the \"without\" model showing a 65% improvement in R² (0.1010 vs. 0.0610). This highlights CatBoost’s robustness, especially with fewer features.\n",
    "  - XGBoost’s negative R² in both cases (-0.1203 vs. -0.0814) indicates it struggles with the dataset, potentially due to overfitting or poor feature interaction handling, with a slight improvement without environmental data.\n",
    "  - RandomForest’s marginal RMSE difference (0.4853 vs. 0.4919) and lower R² with weather/pollution suggest it may overfit to environmental noise.\n",
    "\n",
    "- **Practical Application**:\n",
    "  - The \"without\" model, with a lower RMSE (0.4749) and higher R² (0.1010) for CatBoost, is more accurate and easier to deploy without external data feeds. It can reliably predict demand (e.g., 1 order for \"Bageecha Pizza\" at 12:00) based on time and restaurant activity.\n",
    "  - The \"with\" model’s predictions (e.g., 2 for \"Bageecha Pizza\" with Rainy, AQI=50) might capture weather-related demand shifts (e.g., more indoor orders on rainy days), but its lower accuracy limits its practical utility unless refined.\n",
    "\n",
    "- **Comparison and Implications**:\n",
    "  - The 65% R² increase (0.0610 to 0.1010) and 1.4% RMSE reduction (0.4817 to 0.4749) for CatBoost without weather/pollution suggest that environmental data may be irrelevant or poorly integrated here. This could mean the dataset lacks sufficient weather-demand correlation or that the features (e.g., average temperature) are too coarse.\n",
    "  - The baseline’s unchanged performance (RMSE 0.5181, R² 0.0553) confirms that the core temporal model is the foundation, with environmental additions providing minimal benefit.\n",
    "  - **Significance**: The results indicate that for this dataset, time-based and restaurant features are more reliable predictors than weather and AQI. However, in regions with stronger weather-demand links (e.g., heavy rain increasing delivery orders), environmental data could be valuable with better feature engineering (e.g., binary rain indicator, extreme AQI thresholds).\n",
    "\n",
    "#### Future Improvements\n",
    "- **Feature Engineering**: Reintroduce weather/pollution with targeted features (e.g., rain vs. no rain, AQI > 100) to test their impact.\n",
    "- **Model Tuning**: Optimize hyperparameters for XGBoost and RandomForest to improve R² and reduce negative values.\n",
    "- **Data Enhancement**: Incorporate holidays, promotions, or customer data to boost explanatory power beyond 0.1010 R².\n",
    "\n",
    "### Conclusion\n",
    "The \"without weather and pollution\" model outperforms the \"with\" model for CatBoost, suggesting that environmental data adds little value in this case. The simpler model is a practical choice for baseline forecasting, while the \"with\" model’s potential benefits require further refinement to justify its complexity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
