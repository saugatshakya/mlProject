{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181a446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DISH DEMAND FORECASTER – FINAL POLISHED NOTEBOOK\n",
    "# Author:  Your Name\n",
    "# Date:    2025-10-27\n",
    "# Goal:    Predict hourly demand for top-K dishes per restaurant\n",
    "# =============================================================================\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1. IMPORTS & CONFIG\n",
    "# --------------------------------------------------------------\n",
    "import os\n",
    "import re\n",
    "import joblib\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ── CONFIG ───────────────────────────────────────────────────\n",
    "DATA_PATH      = \"../data/data.csv\"  # Adjust path as needed\n",
    "TOP_K          = 50\n",
    "LAGS           = [1, 2, 3, 6, 12, 24]\n",
    "WINDOWS        = [3, 6, 12, 24]\n",
    "USE_SCALER     = True\n",
    "MODEL_TYPE     = \"xgboost\"\n",
    "TRAIN_FRAC     = 0.8\n",
    "RANDOM_STATE   = 42\n",
    "MODEL_DIR      = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Configuration loaded.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b95149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing utilities ready.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 2. PARSING UTILITIES\n",
    "# --------------------------------------------------------------\n",
    "def parse_order_items(order_str: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"Parse '2 x Pizza, 1 x Coke' → [('Pizza', 2), ('Coke', 1)]\"\"\"\n",
    "    if pd.isna(order_str):\n",
    "        return []\n",
    "    return [(name.strip(), int(qty))\n",
    "            for qty, name in re.findall(r\"(\\d+)\\s*[xX]\\s*([^,]+)\", order_str)]\n",
    "\n",
    "def expand_items(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Expand 'Items in order' into a dictionary of item counts.\"\"\"\n",
    "    df[\"expanded_items\"] = df[\"Items in order\"].fillna(\"\").apply(parse_order_items)\n",
    "    return df\n",
    "\n",
    "print(\"Parsing utilities ready.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8595a2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data: 21,321 rows, 29 columns\n",
      "Found 6 restaurants: ['Swaad', 'Aura Pizzas', 'Dilli Burger Adda', 'Tandoori Junction', 'The Chicken Junction', 'Masala Junction']\n",
      "Pre-processed: 21,321 orders\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 3. LOAD & PREPROCESS\n",
    "# --------------------------------------------------------------\n",
    "def load_and_prepare_data(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load and preprocess raw order data.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"Raw data: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "\n",
    "    # ── datetime ──\n",
    "    dt_col = next((c for c in df.columns\n",
    "                   if \"order\" in c.lower() and (\"placed\" in c.lower() or \"date\" in c.lower())), None)\n",
    "    if not dt_col:\n",
    "        raise ValueError(\"No order datetime column found.\")\n",
    "    df[\"order_datetime\"] = pd.to_datetime(df[dt_col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"order_datetime\"]).copy()\n",
    "    df[\"order_hour\"] = df[\"order_datetime\"].dt.floor(\"h\")\n",
    "\n",
    "    # ── restaurant: clean + one-hot ──\n",
    "    rest_col = \"Restaurant name\"\n",
    "    if rest_col not in df.columns:\n",
    "        raise ValueError(f\"'{rest_col}' column not found.\")\n",
    "    # Standardize restaurant names: strip and keep original case\n",
    "    df[rest_col] = df[rest_col].str.strip()\n",
    "    # Verify unique restaurants\n",
    "    unique_restaurants = df[rest_col].unique()\n",
    "    print(f\"Found {len(unique_restaurants)} restaurants: {list(unique_restaurants)}\")\n",
    "    df = pd.get_dummies(df, columns=[rest_col], prefix=\"rest\", dtype=int)\n",
    "\n",
    "    # ── expand items ──\n",
    "    if \"Items in order\" not in df.columns:\n",
    "        raise ValueError(\"'Items in order' column not found.\")\n",
    "    df = expand_items(df)\n",
    "\n",
    "    print(f\"Pre-processed: {len(df):,} orders\")\n",
    "    return df\n",
    "\n",
    "df = load_and_prepare_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad9f3120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-50 dishes selected (sample: ['Bageecha Pizza', 'Chilli Cheese Garlic Bread', 'Bone in Jamaican Grilled Chicken', 'All About Chicken Pizza', 'Makhani Paneer Pizza'])\n",
      "Aggregated 2,555 active hours.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 4. BUILD HOURLY AGGREGATED TABLE\n",
    "# --------------------------------------------------------------\n",
    "def build_hourly_table(df: pd.DataFrame, top_k: int) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"Aggregate orders to hourly level with top-K dishes.\"\"\"\n",
    "    # ── top-K dishes (global) ──\n",
    "    all_items = Counter()\n",
    "    for items in df[\"expanded_items\"]:\n",
    "        all_items.update({name: qty for name, qty in items})\n",
    "    top_dishes = [name for name, _ in all_items.most_common(top_k)]\n",
    "    print(f\"Top-{len(top_dishes)} dishes selected (sample: {top_dishes[:5]})\")\n",
    "\n",
    "    # ── full hour index ──\n",
    "    hour_idx = pd.date_range(\n",
    "        start=df[\"order_hour\"].min().floor(\"D\"),\n",
    "        end=df[\"order_hour\"].max().ceil(\"D\"),\n",
    "        freq=\"h\"\n",
    "    )\n",
    "    agg = pd.DataFrame(index=hour_idx)\n",
    "    agg.index.name = \"order_hour\"\n",
    "\n",
    "    # ── time features ──\n",
    "    agg[\"hour_of_day\"] = agg.index.hour\n",
    "    agg[\"day_of_week\"] = agg.index.dayofweek\n",
    "    agg[\"is_weekend\"] = agg.index.dayofweek.isin([5, 6]).astype(int)\n",
    "\n",
    "    # ── initialize targets & restaurant cols ──\n",
    "    for dish in top_dishes:\n",
    "        agg[f\"dish__{dish}\"] = 0\n",
    "    agg[\"total_orders\"] = 0\n",
    "\n",
    "    rest_cols = [c for c in df.columns if c.startswith(\"rest_\")]\n",
    "    for col in rest_cols:\n",
    "        agg[col] = 0\n",
    "\n",
    "    # ── aggregate per hour ──\n",
    "    for hour, group in df.groupby(\"order_hour\"):\n",
    "        if hour not in agg.index:\n",
    "            continue\n",
    "        agg.loc[hour, \"total_orders\"] = len(group)\n",
    "\n",
    "        # Restaurant presence: 1 if any order\n",
    "        for col in rest_cols:\n",
    "            agg.loc[hour, col] = 1 if group[col].sum() > 0 else 0\n",
    "\n",
    "        # Dish counts\n",
    "        hour_counts = Counter()\n",
    "        for items in group[\"expanded_items\"]:\n",
    "            hour_counts.update({name: qty for name, qty in items})\n",
    "        for dish in top_dishes:\n",
    "            agg.loc[hour, f\"dish__{dish}\"] = hour_counts.get(dish, 0)\n",
    "\n",
    "    # ── keep only hours with ≥1 order ──\n",
    "    agg = agg[agg[\"total_orders\"] > 0].copy()\n",
    "    print(f\"Aggregated {len(agg):,} active hours.\")\n",
    "    return agg, top_dishes\n",
    "\n",
    "agg, top_dishes = build_hourly_table(df, TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e015b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering → 2,531 rows, 571 cols\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 5. FEATURE ENGINEERING (lags + rolling)\n",
    "# --------------------------------------------------------------\n",
    "def add_temporal_features(agg: pd.DataFrame,\n",
    "                         lags: List[int],\n",
    "                         windows: List[int]) -> pd.DataFrame:\n",
    "    \"\"\"Add lag and rolling window features.\"\"\"\n",
    "    df = agg.copy()\n",
    "\n",
    "    for lag in lags:\n",
    "        df[f\"total_orders_lag_{lag}\"] = df[\"total_orders\"].shift(lag)\n",
    "        for dish in top_dishes:\n",
    "            df[f\"dish__{dish}_lag_{lag}\"] = df[f\"dish__{dish}\"].shift(lag)\n",
    "\n",
    "    for w in windows:\n",
    "        df[f\"total_orders_rollmean_{w}\"] = df[\"total_orders\"].rolling(w, min_periods=1).mean()\n",
    "        for dish in top_dishes:\n",
    "            df[f\"dish__{dish}_rollmean_{w}\"] = df[f\"dish__{dish}\"].rolling(w, min_periods=1).mean()\n",
    "\n",
    "    df = df.dropna().reset_index()  # keep order_hour\n",
    "    print(f\"Feature engineering → {df.shape[0]:,} rows, {df.shape[1]} cols\")\n",
    "    return df\n",
    "\n",
    "agg_with_hour = add_temporal_features(agg, LAGS, WINDOWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0692a29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 restaurants in test but not in train: {'rest_Masala Junction'}\n",
      "Adjusted train/test split to include all restaurants.\n",
      "Train hours: 2,025 | Test hours: 506\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 6. TRAIN / TEST SPLIT (time-based)\n",
    "# --------------------------------------------------------------\n",
    "def ensure_restaurant_coverage(train_agg: pd.DataFrame, test_agg: pd.DataFrame,\n",
    "                              rest_cols: List[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Ensure all restaurants appear in training data.\"\"\"\n",
    "    train_rest = set([c for c in rest_cols if train_agg[c].sum() > 0])\n",
    "    test_rest = set([c for c in rest_cols if test_agg[c].sum() > 0])\n",
    "    missing = test_rest - train_rest\n",
    "    if missing:\n",
    "        print(f\"Warning: {len(missing)} restaurants in test but not in train: {missing}\")\n",
    "        # Move a small portion of test data to train for each missing restaurant\n",
    "        for col in missing:\n",
    "            rest_data = test_agg[test_agg[col] == 1].head(1)\n",
    "            if not rest_data.empty:\n",
    "                train_agg = pd.concat([train_agg, rest_data])\n",
    "                test_agg = test_agg.drop(rest_data.index)\n",
    "        print(\"Adjusted train/test split to include all restaurants.\")\n",
    "    return train_agg, test_agg\n",
    "\n",
    "split_time = agg_with_hour[\"order_hour\"].quantile(TRAIN_FRAC)\n",
    "train_agg = agg_with_hour[agg_with_hour[\"order_hour\"] < split_time].copy()\n",
    "test_agg = agg_with_hour[agg_with_hour[\"order_hour\"] >= split_time].copy()\n",
    "rest_cols = [c for c in agg_with_hour.columns if c.startswith(\"rest_\")]\n",
    "train_agg, test_agg = ensure_restaurant_coverage(train_agg, test_agg, rest_cols)\n",
    "full_agg = agg_with_hour.set_index(\"order_hour\")  # for lag lookup\n",
    "\n",
    "print(f\"Train hours: {len(train_agg):,} | Test hours: {len(test_agg):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f3f0251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 20 (restaurants: 6)\n",
      "Targets: 50\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 7. FEATURE / TARGET LISTS\n",
    "# --------------------------------------------------------------\n",
    "feature_cols = [c for c in train_agg.columns\n",
    "                if not c.startswith(\"dish__\") and c != \"order_hour\"]\n",
    "rest_cols = [c for c in feature_cols if c.startswith(\"rest_\")]\n",
    "target_cols = [f\"dish__{d}\" for d in top_dishes]\n",
    "\n",
    "print(f\"Features: {len(feature_cols)} (restaurants: {len(rest_cols)})\")\n",
    "print(f\"Targets: {len(target_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4b674ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 8. FORECASTER CLASS\n",
    "# --------------------------------------------------------------\n",
    "class DishDemandForecaster:\n",
    "    def __init__(self):\n",
    "        self.top_dishes = top_dishes\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_cols = target_cols\n",
    "        self.scaler = StandardScaler() if USE_SCALER else None\n",
    "        self.model = MultiOutputRegressor(\n",
    "            xgb.XGBRegressor(\n",
    "                n_estimators=400,\n",
    "                max_depth=7,\n",
    "                learning_rate=0.08,\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_jobs=-1,\n",
    "                objective=\"reg:squarederror\"\n",
    "            )\n",
    "        )\n",
    "        self._warned = set()\n",
    "\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        \"\"\"Train the forecaster.\"\"\"\n",
    "        X = df[self.feature_cols].select_dtypes(include=[np.number])\n",
    "        Y = df[self.target_cols]\n",
    "        if self.scaler:\n",
    "            X = pd.DataFrame(self.scaler.fit_transform(X), index=X.index, columns=X.columns)\n",
    "        print(f\"Training on {X.shape[0]:,} hours...\")\n",
    "        self.model.fit(X.values, Y.values)\n",
    "        print(\"Model trained.\\n\")\n",
    "\n",
    "    def predict(self, dt_hour: pd.Timestamp, restaurant: str = None,\n",
    "                round_int: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"Predict dish demand for a specific hour and optional restaurant.\"\"\"\n",
    "        dt_hour = pd.to_datetime(dt_hour).floor(\"h\")\n",
    "        past = full_agg[full_agg.index < dt_hour]\n",
    "        if past.empty:\n",
    "            raise ValueError(f\"No history before {dt_hour}\")\n",
    "        last = past.iloc[-1]\n",
    "\n",
    "        row = pd.Series(0.0, index=self.feature_cols)\n",
    "        row[\"hour_of_day\"] = dt_hour.hour\n",
    "        row[\"day_of_week\"] = dt_hour.dayofweek\n",
    "        row[\"is_weekend\"] = int(dt_hour.dayofweek in [5, 6])\n",
    "\n",
    "        if restaurant:\n",
    "            col = f\"rest_{restaurant.strip()}\"\n",
    "            if col in self.feature_cols:\n",
    "                row[col] = 1\n",
    "            elif restaurant not in self._warned:\n",
    "                print(f\"Warning: Restaurant '{restaurant}' not recognized. Using average behavior.\")\n",
    "                self._warned.add(restaurant)\n",
    "\n",
    "        # Lag/roll features from past\n",
    "        lag_like = [c for c in self.feature_cols if c.startswith((\"total_orders_lag_\",\n",
    "                                                                  \"total_orders_rollmean_\",\n",
    "                                                                  \"dish__\"))]\n",
    "        for c in lag_like:\n",
    "            row[c] = last.get(c, 0)\n",
    "\n",
    "        X_in = pd.DataFrame([row])\n",
    "        if self.scaler:\n",
    "            X_in = pd.DataFrame(self.scaler.transform(X_in), columns=X_in.columns)\n",
    "        X_in = X_in.reindex(columns=self.feature_cols, fill_value=0)\n",
    "\n",
    "        pred = self.model.predict(X_in)[0]\n",
    "        if round_int:\n",
    "            pred = np.maximum(np.round(pred).astype(int), 0)\n",
    "\n",
    "        return (pd.DataFrame({\"dish\": self.top_dishes, \"predicted_qty\": pred})\n",
    "                .sort_values(\"predicted_qty\", ascending=False)\n",
    "                .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "693252f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 2,025 hours...\n",
      "Model trained.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 9. TRAIN\n",
    "# --------------------------------------------------------------\n",
    "forecaster = DishDemandForecaster()\n",
    "forecaster.fit(train_agg.drop(columns=[\"order_hour\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1929ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating test hours...\n",
      "\n",
      "Overall RMSE on test set: 0.616\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 10. EVALUATE ON TEST SET\n",
    "# --------------------------------------------------------------\n",
    "preds = []\n",
    "print(\"\\nEvaluating test hours...\")\n",
    "for _, row in test_agg.iterrows():\n",
    "    dt = row[\"order_hour\"]\n",
    "    active = [c for c in rest_cols if row[c] == 1]\n",
    "    rest_name = active[0][5:] if active else None  # Remove 'rest_' prefix\n",
    "    pred = forecaster.predict(dt, restaurant=rest_name, round_int=False)\n",
    "    preds.append(pred[\"predicted_qty\"].values)\n",
    "\n",
    "Y_test = test_agg[target_cols].values\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, np.array(preds)))\n",
    "print(f\"\\nOverall RMSE on test set: {rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "397c9c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 11. INFERENCE HELPERS\n",
    "# --------------------------------------------------------------\n",
    "def predict_next_hour(restaurant: str = None):\n",
    "    \"\"\"Predict demand for the next hour.\"\"\"\n",
    "    next_h = full_agg.index.max() + pd.Timedelta(hours=1)\n",
    "    return forecaster.predict(next_h, restaurant=restaurant)\n",
    "\n",
    "def forecast_day(date: str, restaurant: str = None):\n",
    "    \"\"\"Forecast demand for all hours in a day.\"\"\"\n",
    "    hours = pd.date_range(f\"{date} 00:00\", f\"{date} 23:00\", freq=\"h\")\n",
    "    results = []\n",
    "    for h in hours:\n",
    "        pred = forecaster.predict(h, restaurant=restaurant)\n",
    "        pred[\"hour\"] = h.strftime(\"%H:%M\")\n",
    "        results.append(pred)\n",
    "    return pd.concat(results).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5d5af23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Next hour (Swaad):\n",
      "                               dish  predicted_qty\n",
      "0                    Bageecha Pizza              1\n",
      "1                      Animal Fries              1\n",
      "2            Bellpepper Onion Pizza              1\n",
      "3            Peri Peri Chicken Melt              1\n",
      "4  Grilled Chicken Smoky BBQ Tender              1\n",
      "5        Chilli Cheese Garlic Bread              1\n",
      "6              Just Pepperoni Pizza              1\n",
      "7    Fried Chicken Peri Peri Tender              1\n",
      "8            Peri Peri Paneer Pizza              1\n",
      "9    Bone in Kabuli Grilled Chicken              1\n",
      "\n",
      "Full day forecast (2025-10-29, Swaad):\n",
      "                                 dish  predicted_qty   hour\n",
      "0                      Bageecha Pizza              1  00:00\n",
      "1                        Animal Fries              1  00:00\n",
      "2              Bellpepper Onion Pizza              1  00:00\n",
      "3              Peri Peri Chicken Melt              1  00:00\n",
      "4    Grilled Chicken Smoky BBQ Tender              1  00:00\n",
      "5          Chilli Cheese Garlic Bread              1  00:00\n",
      "6                Just Pepperoni Pizza              1  00:00\n",
      "7     Grilled Chicken Jamaican Tender              1  00:00\n",
      "8        Murgh Amritsari Garlic Bread              1  00:00\n",
      "9              Peri Peri Paneer Pizza              1  00:00\n",
      "10     Bone in Kabuli Grilled Chicken              1  00:00\n",
      "11            All About Chicken Pizza              1  00:00\n",
      "12              Jamaican Chicken Melt              1  00:00\n",
      "13  Bone in Smoky Bbq Grilled Chicken              0  00:00\n",
      "14        Tipsy Tiger Fresh Lime Soda              0  00:00\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "print(\"\\nNext hour (Swaad):\")\n",
    "print(predict_next_hour(\"Swaad\").head(10))\n",
    "\n",
    "print(\"\\nFull day forecast (2025-10-29, Swaad):\")\n",
    "daily = forecast_day(\"2025-10-29\", \"Swaad\")\n",
    "print(daily.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e3823ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved → models/dish_forecaster_final.pkl\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 12. SAVE MODEL + FULL HISTORY\n",
    "# --------------------------------------------------------------\n",
    "joblib.dump({\n",
    "    \"model\": forecaster,\n",
    "    \"top_dishes\": top_dishes,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"full_agg\": full_agg\n",
    "}, os.path.join(MODEL_DIR, \"dish_forecaster_final.pkl\"))\n",
    "\n",
    "print(f\"\\nModel saved → {MODEL_DIR}/dish_forecaster_final.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
